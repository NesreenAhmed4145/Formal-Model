{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e62cbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "957ee71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Ready to train on GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "New https://pypi.org/project/ultralytics/8.4.7 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.4.6  Python-3.11.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=formal_data_absolute.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=formal_wear_interview_v1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\runs\\detect\\formal_wear_interview_v1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, 16, None, [64, 128, 256]] \n",
      "Model summary: 130 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.3MB 153.3KB/s 35.3s3s<0.3sss2.4s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.70.5 ms, read: 124.874.2 MB/s, size: 74.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\anesr\\OneDrive\\Documents\\GP Project models\\datasets\\formal_wear_filtered\\labels\\train.cache... 22080 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22080/22080  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.30.1 ms, read: 105.427.3 MB/s, size: 66.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\anesr\\OneDrive\\Documents\\GP Project models\\datasets\\formal_wear_filtered\\labels\\val.cache... 711 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 711/711  0.0s\n",
      "Plotting labels to C:\\runs\\detect\\formal_wear_interview_v1\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m MuSGD(lr=0.01, momentum=0.9) with parameter groups 0 weight(decay=0.0), 0 weight(decay=0.0005), 0 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mC:\\runs\\detect\\formal_wear_interview_v1\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30      2.03G     0.9177      1.948      1.249         69        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 5.1it/s 4:33<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.0it/s 3.8s0.2s\n",
      "                   all        711       1204      0.718      0.542      0.588      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/30      2.33G     0.9035      1.331      1.206         71        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 4.9it/s 4:41<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 7.4it/s 3.1s0.1s\n",
      "                   all        711       1204      0.662       0.57      0.637      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/30      2.33G      0.982      1.271      1.254         69        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.1it/s 3:47<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 7.2it/s 3.2s0.1s\n",
      "                   all        711       1204      0.486      0.451       0.51      0.359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/30      2.33G      1.003      1.231      1.272         43        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.3it/s 3:38<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 7.1it/s 3.3s0.1s\n",
      "                   all        711       1204      0.781      0.567      0.666      0.491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/30      2.33G     0.9356      1.135      1.232         67        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.2it/s 3:42<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.7it/s 3.4s0.2s\n",
      "                   all        711       1204      0.527      0.664      0.626      0.474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/30      2.33G     0.8921      1.068      1.201         52        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.2it/s 3:42<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 7.1it/s 3.2s0.1s\n",
      "                   all        711       1204      0.677      0.669      0.718      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/30      2.33G     0.8587      1.016      1.184         76        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.2it/s 3:43<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.9it/s 3.3s0.1s\n",
      "                   all        711       1204      0.587      0.674      0.669      0.503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/30      2.33G     0.8345     0.9859      1.169         62        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.2it/s 3:43<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 7.0it/s 3.3s0.1s\n",
      "                   all        711       1204      0.514       0.71      0.658      0.505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/30      2.33G      0.815     0.9627      1.158         61        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 5.5it/s 4:12<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 4.4it/s 5.2s0.2s\n",
      "                   all        711       1204       0.82      0.736      0.788      0.604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/30      2.33G     0.7926     0.9325      1.142         71        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 4.7it/s 4:53<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 7.5it/s 3.1s0.1s\n",
      "                   all        711       1204      0.592      0.872      0.693       0.55\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/30      2.33G     0.7787     0.9154      1.137         60        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 4.0it/s 5:42<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.4it/s 3.6s0.2s\n",
      "                   all        711       1204      0.871      0.701      0.812      0.626\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/30      2.33G     0.7663     0.8979      1.128         57        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 2.1it/s 10:49<0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 1.5it/s 15.2s0.7s\n",
      "                   all        711       1204      0.758      0.658      0.751      0.587\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/30      2.33G     0.7516     0.8792      1.119         57        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 4.1it/s 5:36<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.5it/s 3.5s0.2s\n",
      "                   all        711       1204      0.625      0.876      0.797      0.618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/30      2.34G      0.739      0.863      1.114         59        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.1it/s 3:46<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.8it/s 3.4s0.2s\n",
      "                   all        711       1204      0.714      0.857      0.822      0.633\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/30      2.34G      0.727     0.8463      1.105         56        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 5.7it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.6it/s 3.5s0.2s\n",
      "                   all        711       1204      0.788      0.866      0.882      0.665\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/30      2.34G     0.7158     0.8285        1.1         62        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 3.8it/s 6:03<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 3.8it/s 6.1s0.3s\n",
      "                   all        711       1204      0.849      0.741      0.843      0.663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/30      2.34G     0.7141      0.824      1.101         67        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 5.2it/s 4:23<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.3it/s 3.6s0.2s\n",
      "                   all        711       1204      0.852      0.829      0.889      0.659\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/30      2.34G      0.701     0.8105      1.094         61        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.1it/s 3:47<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.8it/s 3.4s0.2s\n",
      "                   all        711       1204      0.828      0.853      0.892      0.697\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/30      2.34G     0.6886     0.7926      1.086         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.1it/s 3:48<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.8it/s 3.4s0.2s\n",
      "                   all        711       1204      0.863      0.829      0.895      0.679\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/30      2.34G      0.683      0.785      1.082         69        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.0it/s 3:48<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.9it/s 3.3s0.1s\n",
      "                   all        711       1204      0.846       0.84      0.895      0.703\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/30      2.34G     0.6068     0.6877      1.039         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.2it/s 3:41<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.8it/s 3.4s0.2s\n",
      "                   all        711       1204      0.802      0.847      0.878      0.689\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/30      2.34G     0.5946      0.667      1.033         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.2it/s 3:42<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.9it/s 3.3s0.1s\n",
      "                   all        711       1204      0.783      0.865      0.882      0.685\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/30      2.34G     0.5798     0.6507      1.023         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.2it/s 3:43<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.9it/s 3.3s0.1s\n",
      "                   all        711       1204      0.801      0.865      0.864      0.664\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/30      2.34G     0.5683     0.6372      1.016         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.2it/s 3:42<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 7.0it/s 3.3s0.1s\n",
      "                   all        711       1204      0.798      0.864      0.886       0.69\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/30      2.34G     0.5588     0.6211       1.01         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.2it/s 3:44<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.8it/s 3.4s0.2s\n",
      "                   all        711       1204      0.792       0.87      0.866      0.676\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/30      2.34G     0.5484     0.6009      1.001         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.2it/s 3:42<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 7.1it/s 3.3s0.1s\n",
      "                   all        711       1204      0.783      0.871      0.848      0.665\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/30      2.34G     0.5324     0.5889     0.9933         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.2it/s 3:42<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.9it/s 3.3s0.1s\n",
      "                   all        711       1204        0.8      0.865      0.845      0.673\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/30      2.34G     0.5237     0.5727     0.9873         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.2it/s 3:42<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 7.0it/s 3.3s0.1s\n",
      "                   all        711       1204      0.796      0.859      0.847      0.689\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/30      2.34G     0.5118     0.5547     0.9814         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.2it/s 3:41<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 7.0it/s 3.3s0.1s\n",
      "                   all        711       1204      0.802      0.856      0.847       0.67\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/30      2.34G     0.5025     0.5429     0.9742         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 6.2it/s 3:41<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 7.0it/s 3.3s0.1s\n",
      "                   all        711       1204      0.801      0.856      0.847      0.687\n",
      "\n",
      "30 epochs completed in 2.194 hours.\n",
      "Optimizer stripped from C:\\runs\\detect\\formal_wear_interview_v1\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from C:\\runs\\detect\\formal_wear_interview_v1\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating C:\\runs\\detect\\formal_wear_interview_v1\\weights\\best.pt...\n",
      "Ultralytics 8.4.6  Python-3.11.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "Model summary (fused): 73 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 5.8it/s 4.0s0.2s\n",
      "                   all        711       1204      0.846      0.841      0.895      0.704\n",
      "                 Shirt        547        579      0.824      0.697       0.82      0.653\n",
      "                Jacket        298        308       0.81      0.805      0.852      0.735\n",
      "                   Tie          3          3        0.9          1      0.995      0.619\n",
      "                 Pants        313        314       0.85      0.863      0.914      0.807\n",
      "Speed: 0.1ms preprocess, 1.3ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\runs\\detect\\formal_wear_interview_v1\u001b[0m\n",
      "\n",
      "âœ… Training Complete! Model saved in 'runs/detect/formal_wear_interview_v1/weights/best.pt'\n",
      "ğŸš€ Ready to train on GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "New https://pypi.org/project/ultralytics/8.4.7 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.4.6  Python-3.11.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=formal_data_absolute.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=formal_wear_interview_v12, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\runs\\detect\\formal_wear_interview_v12, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, 16, None, [64, 128, 256]] \n",
      "Model summary: 130 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 462.6157.3 MB/s, size: 81.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\anesr\\OneDrive\\Documents\\GP Project models\\datasets\\formal_wear_filtered\\labels\\train.cache... 22080 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22080/22080  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 256.538.4 MB/s, size: 68.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\anesr\\OneDrive\\Documents\\GP Project models\\datasets\\formal_wear_filtered\\labels\\val.cache... 711 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 711/711  0.0s\n",
      "Plotting labels to C:\\runs\\detect\\formal_wear_interview_v12\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m MuSGD(lr=0.01, momentum=0.9) with parameter groups 0 weight(decay=0.0), 0 weight(decay=0.0005), 0 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mC:\\runs\\detect\\formal_wear_interview_v12\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30      2.04G     0.9177      1.948      1.249         69        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1380/1380 4.9it/s 4:42<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.5it/s 3.6s0.2s\n",
      "                   all        711       1204      0.718      0.542      0.588      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/30      2.34G      0.891      1.378      1.199         73        640: 47% â”â”â”â”â”â•¸â”€â”€â”€â”€â”€â”€ 645/1380 6.0it/s 3:03<2:035\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     41\u001b[39m model = YOLO(\u001b[33m'\u001b[39m\u001b[33myolov8n.pt\u001b[39m\u001b[33m'\u001b[39m) \n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# 3. Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (The Magic Part) ğŸŒŸ\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# ØªÙ… Ø¶Ø¨Ø· Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù„ØªÙ†Ø§Ø³Ø¨ ÙƒØ§Ø±Øª RTX 3060 (6GB VRAM)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mformal_data_absolute.yaml\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ØªØ£ÙƒØ¯ÙŠ Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø¬Ø§Ù†Ø¨ Ø§Ù„ÙƒÙˆØ¯ ÙƒÙ…Ø§ Ø¸Ù‡Ø± ÙÙŠ ØµÙˆØ±ØªÙƒ\u001b[39;49;00m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                         \u001b[49m\u001b[38;5;66;43;03m# Ø¹Ø¯Ø¯ Ø¯ÙˆØ±Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (ÙŠÙ…ÙƒÙ†Ùƒ Ø²ÙŠØ§Ø¯ØªÙ‡Ø§ Ù„Ù€ 50 Ø£Ùˆ 100 Ù„Ø§Ø­Ù‚Ø§Ù‹ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¯Ù‚Ø©)\u001b[39;49;00m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                         \u001b[49m\u001b[38;5;66;43;03m# Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ± Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠ Ù„Ù„ÙŠÙˆÙ„Ùˆ\u001b[39;49;00m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                          \u001b[49m\u001b[38;5;66;43;03m# (Batch Size) Ø±Ù‚Ù… Ø¢Ù…Ù† Ø¬Ø¯Ø§Ù‹ Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù€ 6 Ø¬ÙŠØ¬Ø§\u001b[39;49;00m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;66;43;03m# Ù‡Ø°Ø§ Ø§Ù„Ø³Ø·Ø± ÙŠØ¬Ø¨Ø±Ù‡ ÙŠØ³ØªØ®Ø¯Ù… ÙƒØ§Ø±Øª NVIDIA\u001b[39;49;00m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                         \u001b[49m\u001b[38;5;66;43;03m# Ù„ØªØ³Ø±ÙŠØ¹ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\u001b[39;49;00m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mformal_wear_interview_v1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø°ÙŠ Ø³ÙŠØªÙ… Ø­ÙØ¸Ù‡\u001b[39;49;00m\n\u001b[32m     53\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mâœ… Training Complete! Model saved in \u001b[39m\u001b[33m'\u001b[39m\u001b[33mruns/detect/formal_wear_interview_v1/weights/best.pt\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anesr\\.conda\\envs\\AiProject\\Lib\\site-packages\\ultralytics\\engine\\model.py:774\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    771\u001b[39m     \u001b[38;5;28mself\u001b[39m.trainer.model = \u001b[38;5;28mself\u001b[39m.trainer.get_model(weights=\u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg=\u001b[38;5;28mself\u001b[39m.model.yaml)\n\u001b[32m    772\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anesr\\.conda\\envs\\AiProject\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:244\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    241\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anesr\\.conda\\envs\\AiProject\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:442\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    440\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.scale(\u001b[38;5;28mself\u001b[39m.loss).backward()\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ni - last_opt_step >= \u001b[38;5;28mself\u001b[39m.accumulate:\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    443\u001b[39m     last_opt_step = ni\n\u001b[32m    445\u001b[39m     \u001b[38;5;66;03m# Timed stopping\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anesr\\.conda\\envs\\AiProject\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:694\u001b[39m, in \u001b[36mBaseTrainer.optimizer_step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    692\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.unscale_(\u001b[38;5;28mself\u001b[39m.optimizer)  \u001b[38;5;66;03m# unscale gradients\u001b[39;00m\n\u001b[32m    693\u001b[39m torch.nn.utils.clip_grad_norm_(\u001b[38;5;28mself\u001b[39m.model.parameters(), max_norm=\u001b[32m10.0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m694\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.update()\n\u001b[32m    696\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anesr\\.conda\\envs\\AiProject\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:457\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    451\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    454\u001b[39m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m\n\u001b[32m    455\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anesr\\.conda\\envs\\AiProject\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:352\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    350\u001b[39m retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v.item() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     retval = \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anesr\\.conda\\envs\\AiProject\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:137\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m opt = opt_ref()\n\u001b[32m    136\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anesr\\.conda\\envs\\AiProject\\Lib\\site-packages\\torch\\optim\\optimizer.py:487\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    482\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    483\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    484\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    485\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anesr\\.conda\\envs\\AiProject\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anesr\\.conda\\envs\\AiProject\\Lib\\site-packages\\ultralytics\\optim\\muon.py:218\u001b[39m, in \u001b[36mMuSGD.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    215\u001b[39m     state[\u001b[33m\"\u001b[39m\u001b[33mmomentum_buffer\u001b[39m\u001b[33m\"\u001b[39m] = torch.zeros_like(p)\n\u001b[32m    216\u001b[39m     state[\u001b[33m\"\u001b[39m\u001b[33mmomentum_buffer_SGD\u001b[39m\u001b[33m\"\u001b[39m] = torch.zeros_like(p)\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m update = \u001b[43mmuon_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmomentum_buffer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmomentum\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnesterov\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m p.add_(update.reshape(p.shape), alpha=-(lr * \u001b[38;5;28mself\u001b[39m.muon))\n\u001b[32m    223\u001b[39m \u001b[38;5;66;03m# SGD update\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anesr\\.conda\\envs\\AiProject\\Lib\\site-packages\\ultralytics\\optim\\muon.py:94\u001b[39m, in \u001b[36mmuon_update\u001b[39m\u001b[34m(grad, momentum, beta, nesterov)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m update.ndim == \u001b[32m4\u001b[39m:  \u001b[38;5;66;03m# for the case of conv filters\u001b[39;00m\n\u001b[32m     93\u001b[39m     update = update.view(\u001b[38;5;28mlen\u001b[39m(update), -\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m update = \u001b[43mzeropower_via_newtonschulz5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m update *= \u001b[38;5;28mmax\u001b[39m(\u001b[32m1\u001b[39m, grad.size(-\u001b[32m2\u001b[39m) / grad.size(-\u001b[32m1\u001b[39m)) ** \u001b[32m0.5\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m update\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anesr\\.conda\\envs\\AiProject\\Lib\\site-packages\\ultralytics\\optim\\muon.py:53\u001b[39m, in \u001b[36mzeropower_via_newtonschulz5\u001b[39m\u001b[34m(G, eps)\u001b[39m\n\u001b[32m     51\u001b[39m     A = X @ X.T\n\u001b[32m     52\u001b[39m     B = b * A + c * A @ A\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     X = a * X + B @ X\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m G.size(\u001b[32m0\u001b[39m) > G.size(\u001b[32m1\u001b[39m):\n\u001b[32m     55\u001b[39m     X = X.T\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# 1. ÙØ­Øµ ÙƒØ§Ø±Øª Ø§Ù„Ø´Ø§Ø´Ø© ÙˆØ§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¬Ø§Ù‡Ø²ÙŠØªÙ‡\n",
    "# Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ© Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§Ù‹ Ø¹Ø´Ø§Ù† Ù†ØªØ£ÙƒØ¯ Ø¥Ù†Ù‡ Ù‡ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ù€ NVIDIA Ù…Ø´ Ø§Ù„Ù€ CPU\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ğŸš€ Ready to train on GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    device = 0  # Ø±Ù‚Ù… ÙƒØ§Ø±Øª Ø§Ù„Ø´Ø§Ø´Ø©\n",
    "else:\n",
    "    print(\"âš ï¸ Warning: GPU not found. Training will be slow on CPU.\")\n",
    "    device = 'cpu'\n",
    "\n",
    "# 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ\n",
    "# Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§ 'yolov8n.pt' (Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù€ Nano) Ù„Ø£Ù†Ù‡Ø§ Ø§Ù„Ø£Ø³Ø±Ø¹ ÙˆØ§Ù„Ø£Ø®ÙØŒ ÙˆÙ…Ù†Ø§Ø³Ø¨Ø© Ø¬Ø¯Ø§Ù‹ Ù„Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©\n",
    "model = YOLO('yolov8n.pt') \n",
    "\n",
    "# 3. Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (The Magic Part) ğŸŒŸ\n",
    "# ØªÙ… Ø¶Ø¨Ø· Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù„ØªÙ†Ø§Ø³Ø¨ ÙƒØ§Ø±Øª RTX 3060 (6GB VRAM)\n",
    "results = model.train(\n",
    "    data='formal_data_absolute.yaml',  # ØªØ£ÙƒØ¯ÙŠ Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø¬Ø§Ù†Ø¨ Ø§Ù„ÙƒÙˆØ¯ ÙƒÙ…Ø§ Ø¸Ù‡Ø± ÙÙŠ ØµÙˆØ±ØªÙƒ\n",
    "    epochs=30,                         # Ø¹Ø¯Ø¯ Ø¯ÙˆØ±Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (ÙŠÙ…ÙƒÙ†Ùƒ Ø²ÙŠØ§Ø¯ØªÙ‡Ø§ Ù„Ù€ 50 Ø£Ùˆ 100 Ù„Ø§Ø­Ù‚Ø§Ù‹ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¯Ù‚Ø©)\n",
    "    imgsz=640,                         # Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ± Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠ Ù„Ù„ÙŠÙˆÙ„Ùˆ\n",
    "    batch=16,                          # (Batch Size) Ø±Ù‚Ù… Ø¢Ù…Ù† Ø¬Ø¯Ø§Ù‹ Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù€ 6 Ø¬ÙŠØ¬Ø§\n",
    "    device=device,                     # Ù‡Ø°Ø§ Ø§Ù„Ø³Ø·Ø± ÙŠØ¬Ø¨Ø±Ù‡ ÙŠØ³ØªØ®Ø¯Ù… ÙƒØ§Ø±Øª NVIDIA\n",
    "    workers=4,                         # Ù„ØªØ³Ø±ÙŠØ¹ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "    name='formal_wear_interview_v1'    # Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø°ÙŠ Ø³ÙŠØªÙ… Ø­ÙØ¸Ù‡\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Training Complete! Model saved in 'runs/detect/formal_wear_interview_v1/weights/best.pt'\")\n",
    "# 1. ÙØ­Øµ ÙƒØ§Ø±Øª Ø§Ù„Ø´Ø§Ø´Ø© ÙˆØ§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¬Ø§Ù‡Ø²ÙŠØªÙ‡\n",
    "# Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ© Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§Ù‹ Ø¹Ø´Ø§Ù† Ù†ØªØ£ÙƒØ¯ Ø¥Ù†Ù‡ Ù‡ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ù€ NVIDIA Ù…Ø´ Ø§Ù„Ù€ CPU\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ğŸš€ Ready to train on GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    device = 0  # Ø±Ù‚Ù… ÙƒØ§Ø±Øª Ø§Ù„Ø´Ø§Ø´Ø©\n",
    "else:\n",
    "    print(\"âš ï¸ Warning: GPU not found. Training will be slow on CPU.\")\n",
    "    device = 'cpu'\n",
    "\n",
    "# 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ\n",
    "# Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§ 'yolov8n.pt' (Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù€ Nano) Ù„Ø£Ù†Ù‡Ø§ Ø§Ù„Ø£Ø³Ø±Ø¹ ÙˆØ§Ù„Ø£Ø®ÙØŒ ÙˆÙ…Ù†Ø§Ø³Ø¨Ø© Ø¬Ø¯Ø§Ù‹ Ù„Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©\n",
    "model = YOLO('yolov8n.pt') \n",
    "\n",
    "# 3. Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (The Magic Part) ğŸŒŸ\n",
    "# ØªÙ… Ø¶Ø¨Ø· Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù„ØªÙ†Ø§Ø³Ø¨ ÙƒØ§Ø±Øª RTX 3060 (6GB VRAM)\n",
    "results = model.train(\n",
    "    data='formal_data_absolute.yaml',  # ØªØ£ÙƒØ¯ÙŠ Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø¬Ø§Ù†Ø¨ Ø§Ù„ÙƒÙˆØ¯ ÙƒÙ…Ø§ Ø¸Ù‡Ø± ÙÙŠ ØµÙˆØ±ØªÙƒ\n",
    "    epochs=30,                         # Ø¹Ø¯Ø¯ Ø¯ÙˆØ±Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (ÙŠÙ…ÙƒÙ†Ùƒ Ø²ÙŠØ§Ø¯ØªÙ‡Ø§ Ù„Ù€ 50 Ø£Ùˆ 100 Ù„Ø§Ø­Ù‚Ø§Ù‹ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¯Ù‚Ø©)\n",
    "    imgsz=640,                         # Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ± Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠ Ù„Ù„ÙŠÙˆÙ„Ùˆ\n",
    "    batch=16,                          # (Batch Size) Ø±Ù‚Ù… Ø¢Ù…Ù† Ø¬Ø¯Ø§Ù‹ Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù€ 6 Ø¬ÙŠØ¬Ø§\n",
    "    device=device,                     # Ù‡Ø°Ø§ Ø§Ù„Ø³Ø·Ø± ÙŠØ¬Ø¨Ø±Ù‡ ÙŠØ³ØªØ®Ø¯Ù… ÙƒØ§Ø±Øª NVIDIA\n",
    "    workers=4,                         # Ù„ØªØ³Ø±ÙŠØ¹ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "    name='formal_wear_interview_v1'    # Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø°ÙŠ Ø³ÙŠØªÙ… Ø­ÙØ¸Ù‡\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Training Complete! Model saved in 'runs/detect/formal_wear_interview_v1/weights/best.pt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17b579b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.6  Python-3.11.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "Model summary (fused): 73 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.30.2 ms, read: 87.213.8 MB/s, size: 57.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\anesr\\OneDrive\\Documents\\GP Project models\\datasets\\formal_wear_filtered\\labels\\val.cache... 711 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 711/711  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 9.7it/s 4.6s<0.1s\n",
      "                   all        711       1204      0.847      0.842      0.895      0.703\n",
      "                 Shirt        547        579      0.823      0.701       0.82      0.653\n",
      "                Jacket        298        308      0.811      0.807      0.853      0.736\n",
      "                   Tie          3          3      0.901          1      0.995      0.618\n",
      "                 Pants        313        314      0.852      0.861      0.911      0.806\n",
      "Speed: 0.6ms preprocess, 2.6ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\runs\\detect\\val\u001b[0m\n",
      "Mean Average Precision (mAP50): 0.895\n",
      "Precision: 0.847\n",
      "Recall: 0.842\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# 1. ØªØ­Ù…ÙŠÙ„ Ø£ÙØ¶Ù„ Ù†Ø³Ø®Ø© ÙˆØµÙ„ Ù„Ù‡Ø§ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„\n",
    "# ØªØ£ÙƒØ¯ÙŠ Ø£Ù† Ø§Ù„Ù…Ø³Ø§Ø± ØµØ­ÙŠØ­ ÙƒÙ…Ø§ ÙØ¹Ù„Ù†Ø§ Ø³Ø§Ø¨Ù‚Ø§Ù‹\n",
    "model = YOLO('C:/runs/detect/formal_wear_interview_v1/weights/best.pt')\n",
    "\n",
    "# 2. ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¯Ù‚Ø© Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± (Validation Set)\n",
    "metrics = model.val()\n",
    "\n",
    "# 3. Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø´ÙƒÙ„ Ù…Ù‚Ø±ÙˆØ¡\n",
    "print(f\"Mean Average Precision (mAP50): {metrics.box.map50:.3f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.3f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ece8fa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Formal Attire Analysis ---\n",
      "\n",
      "Results Analysis:\n",
      "- Total Frames Analyzed: 10\n",
      "- Formal Frames Detected: 5\n",
      "- Final Assessment: Not Formal\n",
      "âŒ The attire does not meet formal interview standards.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø°ÙŠ ØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡ (ØªØ£ÙƒØ¯ÙŠ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ø³Ø§Ø±)\n",
    "\n",
    "model = YOLO('C:/runs/detect/formal_wear_interview_v1/weights/best.pt')\n",
    "\n",
    "# 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ\n",
    "video_path = 'C:/Users/anesr/Downloads/3403283-uhd_2160_4096_25fps.mp4'  # Ø¶Ø¹ÙŠ Ù…Ø³Ø§Ø± Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ù‡Ù†Ø§\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Ù…ØªØºÙŠØ±Ø§Øª Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
    "frames_count = 0\n",
    "formal_detections = 0\n",
    "total_frames_to_check = 10  # ØªØ­Ù„ÙŠÙ„ 10 Ø¥Ø·Ø§Ø±Ø§Øª Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© ÙƒÙ…Ø§ Ø°ÙƒØ± ÙÙŠ Ø§Ù„Ø¨Ø­Ø«\n",
    "\n",
    "print(\"--- Starting Formal Attire Analysis ---\")\n",
    "\n",
    "while cap.isOpened() and frames_count < total_frames_to_check:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ\n",
    "    results = model(frame, verbose=False)\n",
    "    \n",
    "    # Ù…Ù†Ø·Ù‚ Ø§Ù„ØªØµÙ†ÙŠÙ (Classification Logic) Ø§Ù„Ù…Ø°ÙƒÙˆØ± ÙÙŠ Ø§Ù„ÙˆØ±Ù‚Ø© [cite: 978]\n",
    "    # Ù†Ø¨Ø­Ø« Ø¹Ù† (Shirt, Jacket, Tie) ÙƒØ¹Ù„Ø§Ù…Ø§Øª Ù„Ù„Ø²ÙŠ Ø§Ù„Ø±Ø³Ù…ÙŠ\n",
    "    found_formal_item = False\n",
    "    for result in results:\n",
    "        names = result.names\n",
    "        for box in result.boxes:\n",
    "            class_id = int(box.cls[0])\n",
    "            label = names[class_id].lower()\n",
    "            \n",
    "            # Ø¥Ø°Ø§ ÙˆØ¬Ø¯ Ø¬Ø§ÙƒÙŠØª Ø£Ùˆ Ù‚Ù…ÙŠØµ Ø£Ùˆ ÙƒØ±Ø§ÙØªØ©\n",
    "            if label in ['shirt', 'jacket', 'tie']:\n",
    "                found_formal_item = True\n",
    "                break\n",
    "    \n",
    "    if found_formal_item:\n",
    "        formal_detections += 1\n",
    "    \n",
    "    frames_count += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# 3. Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£ØºÙ„Ø¨ÙŠØ© Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª\n",
    "status = \"Formal\" if (formal_detections / frames_count) > 0.5 else \"Not Formal\"\n",
    "\n",
    "print(f\"\\nResults Analysis:\")\n",
    "print(f\"- Total Frames Analyzed: {frames_count}\")\n",
    "print(f\"- Formal Frames Detected: {formal_detections}\")\n",
    "print(f\"- Final Assessment: {status}\")\n",
    "\n",
    "if status == \"Formal\":\n",
    "    print(\"âœ… The person is wearing professional formal attire.\")\n",
    "else:\n",
    "    print(\"âŒ The attire does not meet formal interview standards.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
